[
  {
    "objectID": "Trainings/HPC/Intro_to_IJC_HPC.html",
    "href": "Trainings/HPC/Intro_to_IJC_HPC.html",
    "title": "Introduction to the IJC Computational Infrastructure",
    "section": "",
    "text": "This seminar + workshop introduces newcomers to the IJC to the institute’s computing infrastructure. It also serves to keep established researchers updated with latest changes or additions by IT. You can find the presentation here\nTopics covered:\n\nInfrastructure and filesharing\nIJC network and remote connections\nresources available for data storage and computing\nIJC’s high-performance computing cluster (HPC)\n\nIn the second part (working session) we focus on how to use the HPC with practical examples:\n\nSLURM job scheduler\nmonitor and controlling jobs\nsubmitting jobs with sbatch\nserial and array jobs",
    "crumbs": [
      "Trainings",
      "HPC",
      "IJC Infrastructure"
    ]
  },
  {
    "objectID": "Trainings/data_wrangle.html",
    "href": "Trainings/data_wrangle.html",
    "title": "Data manipulation with R",
    "section": "",
    "text": "Data science book: https://r4ds.had.co.nz/explore-intro.html"
  },
  {
    "objectID": "Trainings/Introduction_to_Linux/linux_intro.html",
    "href": "Trainings/Introduction_to_Linux/linux_intro.html",
    "title": "Introduction to Linux and the Shell",
    "section": "",
    "text": "This course gives a brief introduction to Linux and Shell programming.\nTopics covered:\n\nWhat is Linux?\nMoving around the system\nBasic file and directory handling\nFile properties\nFile viewing\nText file manipulation\nVim text editor\nHow to create and run a shell script\nShell variables and control structures (if-else, for-loop, while-loop)\n\nThe presentation from the course can be found here and the exercises (with solutions) here.",
    "crumbs": [
      "Trainings",
      "Linux/Shell",
      "Intro to Linux/Shell"
    ]
  },
  {
    "objectID": "Trainings/Introduction_to_Linux/linux_exercises.html",
    "href": "Trainings/Introduction_to_Linux/linux_exercises.html",
    "title": "Introduction to Linux - Exercises",
    "section": "",
    "text": "Exercise 1:\nGo to the directory ‘/home’ and list its content. How many user with starting with ‘f’? How many regular files aside from directories?\nAnswer\n cd /home\n ls .\n\n\nExercise 2:\nIn your home directory create a new directory called ‘analysis’. Copy the file peaks.bed from the folder /home/shared/ there. Now, create a softlink to the original file and call the file ‘newpeaks.bed’.\nFinally, list all files that end with ‘.bed’ in a single command. What command did you use?\nAnswer\n# go to your home directory\n cd ~\n\n# create directory\n mkdir analysis                     \n\n# enter 'analysis' directory \n cd analysis\n \n# copy 'peaks.bed' to current directory \n cp /home/shared/peaks.bed .  \n\n# create softlink \n ln -s /home/shared/peaks.bed -n newpeaks.bed  \n\n# list all files ending in '.bed' in all three directories\n ls *.bed\n\n\n\n\n\n\nTip\n\n\n\nYou can use the tree command to get a more visual overview of your directory structure:\n\n\n\n\nExercise 3:\nIs bzip2 or gzip the better compression? Which algorithm compresses peaks.bed more?\nAnswer\n# create two extra copies of 'peaks.bed'\n cp peaks.bed peaks1.bed\n cp peaks.bed peaks2.bed\n\n# compress one file with gzip\n gzip peaks1.bed\n\n# compress the other file wit bzip2\n bzip2 peaks2.bed\n\n# compare file sizes with ls\n ls -lth\n\n# =&gt; the file compressed with bzip2 is slightly smaller (6.1K) than the one compressed with gzip (6.4K)\n\n\nExercise 4\nExtract the first and last 10 lines of the file peaks.bed into a new file. How many characters does this file have?\nAnswer\n# extract the first 10 lines\n head -10 peaks.bed &gt; head.peaks\n \n# extract the last 10 lines and append to the previous file\n tail -10 peaks.bed &gt;&gt; head.peaks\n \n# count the number of characters\n wc -c head.peaks\n\n\nExercise 5:\nCreate a file from the first 10 lines of peaks.bed containing only the second and fifth column, where the second column is sorted by increasing size and the fifth column by decreasing size.\nHow many characters does the last line of this file have?\nAnswer\n# extract the first 10 lines, slice column 2, sort numerical and store output in a file\n head -10 peaks.bed | cut -f 2 |sort -n &gt; column2\n\n# do the same but with column 5 and sort in reverse order.\n# then join output with previous file, extract last line and count number of characters (=12)\n head -10 peaks.bed | cut -f 5 |sort -nr| paste column 2 - | tail -1| wc -c\n\n\nExercise 6:\nWhat is the highest and lowest value in column 5 on chrM?\nAnswer\n# find all lines with pattern 'chrM', slice column 5, sort numerical, \n# extract first and last line\ngrep -w chrM peaks.bed | cut -f 5| sort -n| head -1\ngrep -w chrM peaks.bed | cut -f 5| sort -n| tail -1\n\n\nExercise 7:\nWrite a script, that for any given directory lists all files it contains and counts the number of characters of all regular files it contains.\nAnswer\n#! /bin/bash\n\n### Author: Angelika Merkel\n### Date: 30/11/2022\n\n###############################################################################\n### Description:\n### Script script, that for any given directory lists all files it contains and\n### counts the number of characters of all regular files it contains.\n\n###############################################################################\n# assign the script's first argument to a meaningful variable\nDIR=$1\n\n# loop over all elements listed in the specified directory\nfor i in `ls $DIR`\n do\n \n # test if the element listed is a regular file (else could be a directory)\n  if [ -f \"$i\" ]                         \n  \n  # if true, count all characters within the file and return with a message\n    then\n      CHAR=`cat $i| wc -c`\n      echo $i \":\" $CHAR \"characters\"\n  \n  # close conditional\n  fi\n  \n# close for loop\ndone\nFinally, to run the script:\n chmod a+x myscript.sh       # make the file executable\n ./myscript.sh               # run"
  },
  {
    "objectID": "Trainings/Containers/interactive_container.html",
    "href": "Trainings/Containers/interactive_container.html",
    "title": "Interactive shell",
    "section": "",
    "text": "When we run the container, it loads the image and executes the predefined command, if one is defined. Instead of running the predefined command, we can also open an interactive shell in the container.\n\n\n\n\n\n\nExercice 3\n\n\n\n\nTo open an interactive shell in a Singularity container, type: singularity shell local_image_name.sif\n(To exit the container, type exit )\nCheck the user outside and inside the container with: whoami\nCheck the contents of the home directory outside and inside the container:\nNow run the interactive shell with the -C option and verify that the home directory is empty.\n\n\n\nSolution\n\n  singularity shell lolcow.sif\n  whoami\n  exit\n  whoami\n  ls\n  singularity shell lolcow.sif\n  ls\n  exit\n  singularity shell -C lolcow.sif\n  ls",
    "crumbs": [
      "Trainings",
      "Containers",
      "Interactive shell"
    ]
  },
  {
    "objectID": "Trainings/Containers/containers_in_HPC.html",
    "href": "Trainings/Containers/containers_in_HPC.html",
    "title": "Containers in the IJC’s High-Performance Computing Cluster (HPC)",
    "section": "",
    "text": "Not root access in the cluster.\nEvery dependency must be installed by the system administrator.\nRunning containers with the Slurm scheduler.\n\n\n\n\n\n\n\nExercice 7\n\n\n\n\nCreate a bash script to execute the lolcow container inside an Slurm batch job:\n\n#!/bin/bash \n#SBATCH --job-name=run_lolcow\n\nUse sbatch to run the script and check the output:\nModify the script to run the command whoami inside the container\n\n\n\nSolution\n\n  vim lolcow.slm\n  #!/bin/bash \n  #SBATCH --job-name=run_lolcow\n  singularity run lolcow.sif\n  sbatch lolcow.slm",
    "crumbs": [
      "Trainings",
      "Containers",
      "Containers in HPC"
    ]
  },
  {
    "objectID": "Trainings/Containers/build_a_container.html",
    "href": "Trainings/Containers/build_a_container.html",
    "title": "Build a container",
    "section": "",
    "text": "scratch\nAlpine\nUbuntu\nDockerHUb https://hub.docker.com/ –&gt; Rocker, Bioconductor, conda, …\n\n\nSingularity & Apptainer\n * “–fakeroot” or remote build",
    "crumbs": [
      "Trainings",
      "Containers",
      "Build a container"
    ]
  },
  {
    "objectID": "Trainings/Containers/container_sandbox.html",
    "href": "Trainings/Containers/container_sandbox.html",
    "title": "Container sandbox",
    "section": "",
    "text": "Create a sandbox\n\n\n\n\n\n\nAvoid sandboxex\n\n\n\nThe resulting image will become a blackbox"
  },
  {
    "objectID": "Trainings/Containers/run_in_container.html",
    "href": "Trainings/Containers/run_in_container.html",
    "title": "Run in a container",
    "section": "",
    "text": "We can tell the container to run and execute a command with: singularity exec local_image_name.sif command\n\n\n\n\n\n\nExercice 4\n\n\n\n\nCheck the operating system outside the container with: head /etc/os-release\nCheck the operating system inside the container with: singularity exec local_image_name.sif command\n\n\n\nSolution\n\n  head /etc/os-release\n  singularity exec lolcow.sif head /etc/os-release",
    "crumbs": [
      "Trainings",
      "Containers",
      "Run in a container"
    ]
  },
  {
    "objectID": "Trainings/Containers/container_recipe.html",
    "href": "Trainings/Containers/container_recipe.html",
    "title": "Container recipe",
    "section": "",
    "text": "Bootstrap: localimage\nFrom: lolcow.sif\n\n%post\n  apt-get -y update\n  apt-get -y install sl=3.03-17build1\n\n%runscript\n  sl -F\n\n\n\n\n\n\nExercice 6\n\n\n\n\nCreate a file named steam.def with the above code.\nBuild the modified image with the command: apptainer build image_name.sif recipe.def\nRun the newly created container.\n\n\n\nSolution\n\n  vim steam.def\n  apptainer build steam.sif steam.def\n  singularity run steam.sif\n\n\n\n\n\n\n\n\n\nImportance of version reference\n\n\n\nDifferent versions of a dependency may not be 100% compatible.\n\n\nhttps://apptainer.org/docs/user/1.0/index.html",
    "crumbs": [
      "Trainings",
      "Containers",
      "Container recipe"
    ]
  },
  {
    "objectID": "Trainings/Containers/vm_vs_containers.html",
    "href": "Trainings/Containers/vm_vs_containers.html",
    "title": "Virtualization and containerization",
    "section": "",
    "text": "Virtual Machines\nContainer\n\n\n\n\nGuest OS\nEach VM runs on virtual hardware and the kernel is loaded into its own memory region.\nAll containers share the same kernel.\n\n\nCommunication\nThrough Ethernet Devices.\nStandard IPC mechanisms like Signals, pipes, sockets, etc.\n\n\nPerformance\nSmall overhead as the Machine instructions need to be translated from Guest to Host OS.\nNear native performance as compared to the underlying Host OS.\n\n\nStartup time\nTakes up to a few minutes to boot up.\nContainers can be booted up in a few seconds.\n\n\nIsolation\nSharing libraries, files, etc. between guests and between guests and host not natively possible.\nSubdirectories can be transparently mounted and can be shared.\n\n\nStorage\nVMs usually require more storage as the whole OS kernel and associated programs have to be installed and run.\nContainers consume lower amount of storage since the Host OS is shared.\n\n\n\nhttps://www.hifis.net/workshop-materials/general-container/",
    "crumbs": [
      "Trainings",
      "Containers",
      "VM and containerization"
    ]
  },
  {
    "objectID": "Trainings/Introduction_to_R/R_basics.html",
    "href": "Trainings/Introduction_to_R/R_basics.html",
    "title": "R basics",
    "section": "",
    "text": "This course gives a brief introduction to R and R programming basics. The presentation is available here\nTopics covered:\n\nWhy R and what is R?\nIntroduction to RStudio\nWorkflow best practices\nPractical session programming basics:\n\nClasses and types of objects\nAccessing objects\nFunctions\nControl structures\n\nPractical session data analysis:\n\nImporting/exporting data\nExploratory data analysis\nBasic plots\n\n\nFor the practical session we follow Chapters 4, 9, 13 and 14 of the book by D.Peng “R Programming for Data Science” (2022). The data analysis example can be found here.",
    "crumbs": [
      "Trainings",
      "R",
      "R basics"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IJC BIT Workshops",
    "section": "",
    "text": "This site has been created by the Bioinformatics Team (BIT) unit a the Josep Carreras Leukaemia Research Institute (IJC) to store materials and links for workshops we are hosting during the year 2022-2023. We encourage you to add any comments or thoughts you may have!\nGeneral topics\n\nR and R packages\nBioconductor\nLinux and beyond\nHigh performance computing (HPC)\nData management\nTools for reproducible research\n\nIf you are interested in any particular topic for a future workshop, please let us know by sending us a mail or simply passing by our office.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "IJC BIT Workshops",
    "section": "",
    "text": "This site has been created by the Bioinformatics Team (BIT) unit a the Josep Carreras Leukaemia Research Institute (IJC) to store materials and links for workshops we are hosting during the year 2022-2023. We encourage you to add any comments or thoughts you may have!\nGeneral topics\n\nR and R packages\nBioconductor\nLinux and beyond\nHigh performance computing (HPC)\nData management\nTools for reproducible research\n\nIf you are interested in any particular topic for a future workshop, please let us know by sending us a mail or simply passing by our office.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "Trainings/Introduction_to_R/Example_data_analysis.html",
    "href": "Trainings/Introduction_to_R/Example_data_analysis.html",
    "title": "Example data analysis",
    "section": "",
    "text": "Principal functions reading data into R\n\nread.table, read.csv (tabular data)\nreadLines (text file)\nload (read in saved workspaces)\nsource (for reading in R code files)\n\n\n\n\nread.table() is one of the most commonly used functions for reading data. The help file is definitely worth reading in its entirety.\nThe read.table() function has a few important arguments:\n\nfile, the name of a file, or a connection\nheader, logical indicating if the file has a header line\nsep, a string indicating how the columns are separated\ncolClasses, a character vector indicating the class of each column in the dataset\nnrows, the number of rows in the dataset. By default read.table() reads an entire file.\ncomment.char, a character string indicating the comment character. This defaults to “#”.\nskip, the number of lines to skip from the beginning\nstringsAsFactors, should character variables be coded as factors? This defaults to TRUE.\n\n\n\n\n\n\n\n\nTip\n\n\n\nReading larger datasets with R\nread.table() automatically estimates various parameters to store data. If you provide these this significantly speeds up the reading of large data sets.\n\nSet comment.char = \"\" if there are no commented lines in your file.\nUse the colClasses argument. Specifying this option instead of using the default can make ‘read.table’ run MUCH faster, often twice as fast. In order to use this option, you have to know the class of each column in your data frame. If all of the columns are “numeric”, for example, then you can just set colClasses = \"numeric\".\nSet nrows. This doesn’t make R run faster but it helps with memory usage. A mild overestimate is okay.\n\n\n\n\n\n\n\n# use default parameters, missing parameters are estimated\ndata &lt;- read.table(file = \"data/my_data.txt\") \n\n# assign parameters\ndata &lt;- read.table(file = \"data/my_data.txt\", \n                   comment.char = \"\", \n                   header = TRUE,\n                   colClasses = c(rep(\"numeric\",4), \"factor\")\n                   )"
  },
  {
    "objectID": "Trainings/Introduction_to_R/Example_data_analysis.html#import-data",
    "href": "Trainings/Introduction_to_R/Example_data_analysis.html#import-data",
    "title": "Example data analysis",
    "section": "",
    "text": "Principal functions reading data into R\n\nread.table, read.csv (tabular data)\nreadLines (text file)\nload (read in saved workspaces)\nsource (for reading in R code files)\n\n\n\n\nread.table() is one of the most commonly used functions for reading data. The help file is definitely worth reading in its entirety.\nThe read.table() function has a few important arguments:\n\nfile, the name of a file, or a connection\nheader, logical indicating if the file has a header line\nsep, a string indicating how the columns are separated\ncolClasses, a character vector indicating the class of each column in the dataset\nnrows, the number of rows in the dataset. By default read.table() reads an entire file.\ncomment.char, a character string indicating the comment character. This defaults to “#”.\nskip, the number of lines to skip from the beginning\nstringsAsFactors, should character variables be coded as factors? This defaults to TRUE.\n\n\n\n\n\n\n\n\nTip\n\n\n\nReading larger datasets with R\nread.table() automatically estimates various parameters to store data. If you provide these this significantly speeds up the reading of large data sets.\n\nSet comment.char = \"\" if there are no commented lines in your file.\nUse the colClasses argument. Specifying this option instead of using the default can make ‘read.table’ run MUCH faster, often twice as fast. In order to use this option, you have to know the class of each column in your data frame. If all of the columns are “numeric”, for example, then you can just set colClasses = \"numeric\".\nSet nrows. This doesn’t make R run faster but it helps with memory usage. A mild overestimate is okay.\n\n\n\n\n\n\n\n# use default parameters, missing parameters are estimated\ndata &lt;- read.table(file = \"data/my_data.txt\") \n\n# assign parameters\ndata &lt;- read.table(file = \"data/my_data.txt\", \n                   comment.char = \"\", \n                   header = TRUE,\n                   colClasses = c(rep(\"numeric\",4), \"factor\")\n                   )"
  },
  {
    "objectID": "Trainings/Introduction_to_R/Example_data_analysis.html#data-qc-and-exploration",
    "href": "Trainings/Introduction_to_R/Example_data_analysis.html#data-qc-and-exploration",
    "title": "Example data analysis",
    "section": "2. Data QC and exploration",
    "text": "2. Data QC and exploration\nOnce you have imported your data it is always a good idea to inspect your data object:\n\nhead() = displays the first parts of an object\nattributes() = lists the attributes of an object\nstr() = displays the internal structure of an R object or a diagnostic function\nRStudio viewer view()\n\nYou may need to adjust the way you import your data!\n\nNow, you can start exploring your data\n\n# rename the object\niris &lt;- data\n\n# basic summary statistics\nsummary(iris)\n\n# density distribution\nplot(density(iris$Sepal.Length))\n\n# value distribution by group\nboxplot(iris$Sepal.Length ~ iris$Species, col = c(\"black\",\"red\",\"green\"))\n\n# pairwise value plots\npairs(iris, col = iris$Species)"
  },
  {
    "objectID": "Trainings/Introduction_to_R/Example_data_analysis.html#data-analysis",
    "href": "Trainings/Introduction_to_R/Example_data_analysis.html#data-analysis",
    "title": "Example data analysis",
    "section": "3. Data analysis",
    "text": "3. Data analysis\nLets find out how Sepal length and Petal length are related\n\n# examine the relationship between Sepal and Petal Length\nplot(iris$Sepal.Length, iris$Petal.Length, col = iris$Species)\n\n# calculate Pearson correlation\ncor.test(iris$Sepal.Length, iris$Petal.Length)\n\n# =&gt; Great! Sepal.Length and Petal.Length are significantly positive correlated. Let's capture this\n# insight in a nicer informative plot.\n\n\n# FINAL PLOT\n \nplot(iris$Sepal.Length, iris$Petal.Length,            # x variable, y variable\n     col  = iris$Species,                             # colour by species\n     pch  = 16,                                       # type of point to use\n     xlab = \"Sepal Length\",                           # x axis label\n     ylab = \"Petal Length\",                           # y axis label\n     main = \"Flower characteristics in Iris\")         # plot title \n\n# legend with titles of iris$Species and colour 1:3, point type pch at coords (x,y)\nlegend(\"topleft\", legend = levels(iris$Species), col = c(1:3), pch =16)\n\n# text at coords (x,y) with label correlation test\ntext(x = 7.5, y = 2, labels = \"cor = 0.871\\np &lt; 2.2e-16\")\n\nFor more on basic R plots see R Base Graphics: An Idiots Guide"
  },
  {
    "objectID": "Trainings/Introduction_to_R/Example_data_analysis.html#export-results",
    "href": "Trainings/Introduction_to_R/Example_data_analysis.html#export-results",
    "title": "Example data analysis",
    "section": "4. Export results",
    "text": "4. Export results\nAfter you have finished you analysis you may want so save your results for later:\nSaving images\n\nexport with RStudio through Plots &gt;&gt; save\nalternatively use jpeg(), png(), svg() or pdf()\n\n\n# open graphics device\npng(file = \"my_plot.png\", width = 480, height = 480)\n\n# plot\nplot(iris$Sepal.Length, iris$Petal.Length,            # x variable, y variable\n     col  = iris$Species,                             # colour by species\n     pch  = 16,                                       # type of point to use\n     xlab = \"Sepal Length\",                           # x axis label\n     ylab = \"Petal Length\",                           # y axis label\n     main = \"Flower characteristics in Iris\")         # plot title \n\n# legend with titles of iris$Species and colour 1:3, point type pch at coords (x,y)\nlegend(\"topleft\", legend = levels(iris$Species), col = c(1:3), pch =16)\n\n# text at coords (x,y) with label correlation test\ntext(x = 7.5, y = 2, labels = \"cor = 0.871\\np &lt; 2.2e-16\")\n\n# close the device\ndev.off()\n\nFunctions for writing data to files\n\nwrite.table or write.csv (writing tabular data to text files, i.e. CSV, or connections)\nwriteLines(writing character data line-by-line to a file or connection)\nsave (saving an arbitrary number of R objects in binary format (possibly compressed) to a file)\n\n\n# write your results to a file\nwrite.table(iris,                       # dataframe\n            file = \"results.csv\",       # filename\n            sep  = \";\",                 # field seperator\n            col.names = TRUE,           # include header (default = TRUE)\n            row.names = FALSE,          # include row names (default = TRUE)\n            quote = FALSE)              # quote characters and factors\n\n# save your workspace\nsave(file = \"my_workspace.Rdata\")       # warning: this occupies the most space\n\n# save multiple objects\nsave(iris, data, file = \"my_two_objects.Rdata\")\n\n# save a single data object (compressed)\nsaveRDS(iris,                           #  data object\n        file = \"iris.rds\")              #  file name"
  },
  {
    "objectID": "Trainings/Containers/Intro_to_containers.html",
    "href": "Trainings/Containers/Intro_to_containers.html",
    "title": "Introduction to the world of containers",
    "section": "",
    "text": "Packages code and all its dependencies.\nRuns anywhere with a compatible kernel.\n\n\n\n\n\n\n\nExercice 1\n\n\n\n\nGo to the VPN and log in to the Linux course machine: https://vpn.carrerasresearch.org/static/sslvpn/portal/\nFind a container named “lolcow” from “godlovedc” on Docker Hub: https://hub.docker.com/\nGo back to the Linux terminal and type: singularity run docker://container/name\n\n\n\nSolution\n\n  singularity run docker://godlovedc/lolcow",
    "crumbs": [
      "Trainings",
      "Containers",
      "Intro to containers"
    ]
  },
  {
    "objectID": "Trainings/Containers/docker_vs_singularity.html",
    "href": "Trainings/Containers/docker_vs_singularity.html",
    "title": "Docker vs Singularity",
    "section": "",
    "text": "Sudo in docker\nSingularity runs with the same user that starts the container while the Docker daemon runs as root.\n\n\nHost files access\nDefault Behavior: Docker isolates the container from the host machine by default. Singularity mounts the /home directory of the user running the container.\n\n\n\n\n\n\nSide effects of mounting the home directory\n\n\n\nAll user customization files will be in the container when it runs. This can break the isolation/reproducibility concept, such as having user-defined R libraries.\nIt is recommended to run Singularity with –no-home or even with –containall (-C) and bind only the required directories.",
    "crumbs": [
      "Trainings",
      "Containers",
      "Docker vs Singularity"
    ]
  },
  {
    "objectID": "Trainings/Containers/how_containers_work.html",
    "href": "Trainings/Containers/how_containers_work.html",
    "title": "How containers work?",
    "section": "",
    "text": "Namespaces for access control\ncgroups for resources management\n\nFor a detailed explanation, see Iván Moreno’s article on Medium",
    "crumbs": [
      "Trainings",
      "Containers",
      "How containers work"
    ]
  },
  {
    "objectID": "Trainings/Containers/running_instances.html",
    "href": "Trainings/Containers/running_instances.html",
    "title": "Running instances",
    "section": "",
    "text": "singularity images list"
  },
  {
    "objectID": "Trainings/Containers/sequera_containers.html",
    "href": "Trainings/Containers/sequera_containers.html",
    "title": "Seqera containers",
    "section": "",
    "text": "https://seqera.io/containers/"
  },
  {
    "objectID": "Trainings/Containers/pull_container.html",
    "href": "Trainings/Containers/pull_container.html",
    "title": "Pulling container images",
    "section": "",
    "text": "You can create your own container image from ‘scratch,’ but normally you will start with an image that somebody else has already created. o do so, you can either run the image straight from the external repository or download it locally and run it later.\n\n\n\n\n\n\nExercice 2\n\n\n\n\nGo back to the Linux terminal and type: singularity pull local_image_name.sif docker://container/name to download the image.\nRun the local image with: singularity run local_image_name.sif\n\n\n\nSolution\n\n  singularity pull lolcow.sif docker://godlovedc/lolcow\n  singularity run lolcow.sif",
    "crumbs": [
      "Trainings",
      "Containers",
      "Pulling container images"
    ]
  },
  {
    "objectID": "Trainings/Containers/pipeline_example.html",
    "href": "Trainings/Containers/pipeline_example.html",
    "title": "Nexflow pipeline in a container",
    "section": "",
    "text": "Solution\n\n  Module load Nextflow\n  Module load singularity\n  nextflow run rnaseq-nf -with-singularity"
  },
  {
    "objectID": "Trainings/Containers/files_access.html",
    "href": "Trainings/Containers/files_access.html",
    "title": "Files access",
    "section": "",
    "text": "Persisten changes\n\n\n\nAll changes made inside a container are lost when the container is stopped. If we need the changes to be persistent, we must use a folder from the host machine.\n\n\nIf we need to access files outside the container, we can “BIND” folders from the host machine to the container: singularity shell  -B /host/path:/path/in/container local_image_name.sif\n\n\n\n\n\n\nExercice 5\n\n\n\n\nCreate a folder named “dummy” on the host machine.\nOpen a terminal inside the container with the -C option (--containall).\nCheck that there is no “dummy” folder.\nExit the container and enter again, but this time use the bind (-B) option to mount the directory you have created to “/dummy” inside the container.\nCreate a text file inside the “/dummy” directory inside the container with touch test.txt\nExit the container and check that the file you created inside the container is in the “dummy” directory of the host machine:\n\n\n\nSolution\n\n  mkdir dummy\n  singularity shell -C lolcow.sif\n  ls\n  cd /dummy\n  exit\n  singularity shell -C -B dummy:/dummy lolcow.sif\n  cd /dummy\n  touch test.txt\n  ls\n  exit\n  cd dummy\n  ls",
    "crumbs": [
      "Trainings",
      "Containers",
      "Files access"
    ]
  },
  {
    "objectID": "Trainings/0Basic_concepts.html",
    "href": "Trainings/0Basic_concepts.html",
    "title": "Basic concepts",
    "section": "",
    "text": "rstudio: -import data: -quarto: -viewer: -github: -options:\nfunction: -arguments -return -environment*"
  },
  {
    "objectID": "Trainings/Introduction_to_Linux/Linux_exercises.postJune2024.html",
    "href": "Trainings/Introduction_to_Linux/Linux_exercises.postJune2024.html",
    "title": "Introduction to Linux - Exercises",
    "section": "",
    "text": "Exercise 1:\nGo to the root directory and list its content. How many other files aside from directories ? How many directories starting with ‘s’?\nAnswer\n cd /\n ls .      # 1 regular files, 6 softlinks\n ls -d s*  # 4 directories, \n           # Note that `ls s*` will list the contents of all directories\n           # starting with 's\"' \n\n\nExercise 2:\nIn your home directory create a new directory called ‘analysis’. Copy the file ‘/home/shared/peaks.bed’ to this directory. Now, create a softlink to the original file and call it ‘softlink_peaks.bed’.\nFinally, list all files that end with ‘.bed’ in a single command.\nAnswer\n# go to your home directory\n cd ~\n\n# create directory\n mkdir analysis                     \n\n# enter 'analysis' directory \n cd analysis\n \n# copy 'peaks.bed' to current directory \n cp /home/shared/peaks.bed .  \n\n# create softlink \n ln -s /home/shared/peaks.bed -n softlink_peaks.bed  \n\n# list all files ending in '.bed' in all three directories\n ls *.bed\n\n\nExercise 3:\nIs bzip2 or gzip the better compression? Which algorithm compresses peaks.bed more?\nAnswer\n# create two extra copies of 'peaks.bed'\n cp peaks.bed peaks1.bed\n cp peaks.bed peaks2.bed\n\n# compress one file with gzip\n gzip peaks1.bed\n\n# compress the other file wit bzip2\n bzip2 peaks2.bed\n\n# compare file sizes with ls\n ls -lth\n\n# =&gt; the file compressed with bzip2 is slightly smaller (6.1K) than the one compressed with gzip (6.4K)\n\n\nExercise 4\nExtract the first and last 10 lines of the file peaks.bed into a new file. How many characters does this file have?\nAnswer\n# extract the first 10 lines\n head -10 peaks.bed &gt; head.peaks\n \n# extract the last 10 lines and append to the previous file\n tail -10 peaks.bed &gt;&gt; head.peaks\n \n# count the number of characters\n wc -c head.peaks\n\n\nExercise 5:\nExtract the first 10 lines of the second and fifth column from of peaks.bed. Create a file where the (originally) second column is sorted by increasing size and the fifth column by decreasing size.\nHow many characters does the last line of this file have?\nAnswer\n# extract the first 10 lines, slice column 2, sort numerical and store output in a file\n head -10 peaks.bed | cut -f 2 |sort -n &gt; column2\n\n# do the same but with column 5 and sort in reverse order.\n# then join output with previous file, extract last line and count number of characters (=12)\n head -10 peaks.bed | cut -f 5 |sort -nr| paste column 2 - | tail -1| wc -c\n\n\nExercise 6:\nWhat is the highest and lowest value in column 5 on chrM?\nAnswer\n# find all lines with pattern 'chrM', slice column 5, sort numerical, \n# extract first and last line\ngrep -w chrM peaks.bed | cut -f 5| sort -n| head -1\ngrep -w chrM peaks.bed | cut -f 5| sort -n| tail -1\n\n\nExercise 7:\nWrite a script, that for any given directory lists all files it contains and counts the number of characters of all regular files it contains.\nAnswer\n#! /bin/bash\n\n### Author: Angelika Merkel\n### Date: 30/11/2022\n\n###############################################################################\n### Description:\n### Script script, that for any given directory lists all files it contains and\n### counts the number of characters of all regular files it contains.\n\n###############################################################################\n# assign the script's first argument to a meaningful variable\nDIR=$1\n\n# loop over all elements listed in the specified directory\nfor i in `ls $DIR`\n do\n \n # test if the element listed is a regular file (else could be a directory)\n  if [ -f \"$i\" ]                         \n  \n  # if true, count all characters within the file and return with a message\n    then\n      CHAR=`cat $i| wc -c`\n      echo $i \":\" $CHAR \"characters\"\n  \n  # close conditional\n  fi\n  \n# close for loop\ndone\nFinally, to run the script:\n chmod a+x myscript.sh       # make the file executable\n ./myscript.sh               # run"
  },
  {
    "objectID": "Trainings/Visualizations_with_ggplot2/Visualizations_with_ggplot2.html",
    "href": "Trainings/Visualizations_with_ggplot2/Visualizations_with_ggplot2.html",
    "title": "Data visualization in R with the ggplot2 package",
    "section": "",
    "text": "This workshop introduces the ggplot2 R package for data visualization ( course presentation available here)\nTopics covered:\n\nWhy ggplot2?\nBase R and the tidyverse\nBuilding up your plot with ggplot()\nAestetics and geoms\nTypes of plots for one, two or multiple numerical/categorical variables\n\nFor this course we follow the Chapter: ‘Data visualization’ in the book R for Data Science (2nd edition) by Wickham et al. This includes the practical session and exercises.",
    "crumbs": [
      "Trainings",
      "R",
      "Visualizations with ggplot2"
    ]
  },
  {
    "objectID": "Trainings/Advancing_with_the_Shell/Advancing_with_the_Shell.html",
    "href": "Trainings/Advancing_with_the_Shell/Advancing_with_the_Shell.html",
    "title": "Advancing with the Shell",
    "section": "",
    "text": "In this course we teach advanced functionality of the shell (specifically bash). The course presentation is available here\nTopics covered:\n\nCustomizing your Shell\nBash: Expansions ans substitution\nRegular expression\nFile manipulations with awk and sed",
    "crumbs": [
      "Trainings",
      "Linux/Shell",
      "The Shell advanced"
    ]
  }
]
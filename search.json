[
  {
    "objectID": "Trainings/HPC/Intro_to_IJC_HPC.html",
    "href": "Trainings/HPC/Intro_to_IJC_HPC.html",
    "title": "Introduction to the IJC Computational Infrastructure",
    "section": "",
    "text": "This seminar + workshop introduces newcomers to the IJC to the institute’s computing infrastructure. It also serves to keep established researchers updated with latest changes or additions by IT. You can find the presentation here\nTopics covered:\n\nInfrastructure and filesharing\nIJC network and remote connections\nresources available for data storage and computing\nIJC’s high-performance computing cluster (HPC)\n\nIn the second part (working session) we focus on how to use the HPC with practical examples:\n\nSLURM job scheduler\nmonitor and controlling jobs\nsubmitting jobs with sbatch\nserial and array jobs",
    "crumbs": [
      "Trainings",
      "HPC",
      "IJC Infrastructure"
    ]
  },
  {
    "objectID": "Trainings/data_wrangle.html",
    "href": "Trainings/data_wrangle.html",
    "title": "Data manipulation with R",
    "section": "",
    "text": "Data science book: https://r4ds.had.co.nz/explore-intro.html"
  },
  {
    "objectID": "Trainings/Introduction_to_Linux/linux_intro.html",
    "href": "Trainings/Introduction_to_Linux/linux_intro.html",
    "title": "Introduction to Linux and the Shell",
    "section": "",
    "text": "This course gives a brief introduction to Linux and Shell programming.\nTopics covered:\n\nWhat is Linux?\nMoving around the system\nBasic file and directory handling\nFile properties\nFile viewing\nText file manipulation\nVim text editor\nHow to create and run a shell script\nShell variables and control structures (if-else, for-loop, while-loop)\n\nThe presentation from the course can be found here and the exercises (with solutions) here.",
    "crumbs": [
      "Trainings",
      "Linux/Shell",
      "Intro to Linux/Shell"
    ]
  },
  {
    "objectID": "Trainings/Introduction_to_Linux/linux_exercises.html",
    "href": "Trainings/Introduction_to_Linux/linux_exercises.html",
    "title": "Introduction to Linux - Exercises",
    "section": "",
    "text": "Exercise 1:\nGo to the directory ‘/home’ and list its content. How many user with starting with ‘f’? How many regular files aside from directories?\nAnswer\n cd /home\n ls .\n\n\nExercise 2:\nIn your home directory create a new directory called ‘analysis’. Copy the file peaks.bed from the folder /home/shared/ there. Now, create a softlink to the original file and call the file ‘newpeaks.bed’.\nFinally, list all files that end with ‘.bed’ in a single command. What command did you use?\nAnswer\n# go to your home directory\n cd ~\n\n# create directory\n mkdir analysis                     \n\n# enter 'analysis' directory \n cd analysis\n \n# copy 'peaks.bed' to current directory \n cp /home/shared/peaks.bed .  \n\n# create softlink \n ln -s /home/shared/peaks.bed -n newpeaks.bed  \n\n# list all files ending in '.bed' in all three directories\n ls *.bed\n\n\n\n\n\n\nTip\n\n\n\nYou can use the tree command to get a more visual overview of your directory structure:\n\n\n\n\nExercise 3:\nIs bzip2 or gzip the better compression? Which algorithm compresses peaks.bed more?\nAnswer\n# create two extra copies of 'peaks.bed'\n cp peaks.bed peaks1.bed\n cp peaks.bed peaks2.bed\n\n# compress one file with gzip\n gzip peaks1.bed\n\n# compress the other file wit bzip2\n bzip2 peaks2.bed\n\n# compare file sizes with ls\n ls -lth\n\n# =&gt; the file compressed with bzip2 is slightly smaller (6.1K) than the one compressed with gzip (6.4K)\n\n\nExercise 4\nExtract the first and last 10 lines of the file peaks.bed into a new file. How many characters does this file have?\nAnswer\n# extract the first 10 lines\n head -10 peaks.bed &gt; head.peaks\n \n# extract the last 10 lines and append to the previous file\n tail -10 peaks.bed &gt;&gt; head.peaks\n \n# count the number of characters\n wc -c head.peaks\n\n\nExercise 5:\nCreate a file from the first 10 lines of peaks.bed containing only the second and fifth column, where the second column is sorted by increasing size and the fifth column by decreasing size.\nHow many characters does the last line of this file have?\nAnswer\n# extract the first 10 lines, slice column 2, sort numerical and store output in a file\n head -10 peaks.bed | cut -f 2 |sort -n &gt; column2\n\n# do the same but with column 5 and sort in reverse order.\n# then join output with previous file, extract last line and count number of characters (=12)\n head -10 peaks.bed | cut -f 5 |sort -nr| paste column 2 - | tail -1| wc -c\n\n\nExercise 6:\nWhat is the highest and lowest value in column 5 on chrM?\nAnswer\n# find all lines with pattern 'chrM', slice column 5, sort numerical, \n# extract first and last line\ngrep -w chrM peaks.bed | cut -f 5| sort -n| head -1\ngrep -w chrM peaks.bed | cut -f 5| sort -n| tail -1\n\n\nExercise 7:\nWrite a script, that for any given directory lists all files it contains and counts the number of characters of all regular files it contains.\nAnswer\n#! /bin/bash\n\n### Author: Angelika Merkel\n### Date: 30/11/2022\n\n###############################################################################\n### Description:\n### Script script, that for any given directory lists all files it contains and\n### counts the number of characters of all regular files it contains.\n\n###############################################################################\n# assign the script's first argument to a meaningful variable\nDIR=$1\n\n# loop over all elements listed in the specified directory\nfor i in `ls $DIR`\n do\n \n # test if the element listed is a regular file (else could be a directory)\n  if [ -f \"$i\" ]                         \n  \n  # if true, count all characters within the file and return with a message\n    then\n      CHAR=`cat $i| wc -c`\n      echo $i \":\" $CHAR \"characters\"\n  \n  # close conditional\n  fi\n  \n# close for loop\ndone\nFinally, to run the script:\n chmod a+x myscript.sh       # make the file executable\n ./myscript.sh               # run"
  },
  {
    "objectID": "Trainings/Introduction_to_R/R_basics.html",
    "href": "Trainings/Introduction_to_R/R_basics.html",
    "title": "R basics",
    "section": "",
    "text": "This course gives a brief introduction to R and R programming basics. The presentation is available here\nTopics covered:\n\nWhy R and what is R?\nIntroduction to RStudio\nWorkflow best practices\nPractical session programming basics:\n\nClasses and types of objects\nAccessing objects\nFunctions\nControl structures\n\nPractical session data analysis:\n\nImporting/exporting data\nExploratory data analysis\nBasic plots\n\n\nFor the practical session we follow Chapters 4, 9, 13 and 14 of the book by D.Peng “R Programming for Data Science” (2022). The data analysis example can be found here.",
    "crumbs": [
      "Trainings",
      "R",
      "R basics"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IJC BIT Workshops",
    "section": "",
    "text": "This site has been created by the Bioinformatics Team (BIT) unit a the Josep Carreras Leukaemia Research Institute (IJC) to store materials and links for workshops we are hosting during the year 2022-2023. We encourage you to add any comments or thoughts you may have!\nGeneral topics\n\nR and R packages\nBioconductor\nLinux and beyond\nHigh performance computing (HPC)\nData management\nTools for reproducible research\n\nIf you are interested in any particular topic for a future workshop, please let us know by sending us a mail or simply passing by our office.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "IJC BIT Workshops",
    "section": "",
    "text": "This site has been created by the Bioinformatics Team (BIT) unit a the Josep Carreras Leukaemia Research Institute (IJC) to store materials and links for workshops we are hosting during the year 2022-2023. We encourage you to add any comments or thoughts you may have!\nGeneral topics\n\nR and R packages\nBioconductor\nLinux and beyond\nHigh performance computing (HPC)\nData management\nTools for reproducible research\n\nIf you are interested in any particular topic for a future workshop, please let us know by sending us a mail or simply passing by our office.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "Trainings/Introduction_to_R/Example_data_analysis.html",
    "href": "Trainings/Introduction_to_R/Example_data_analysis.html",
    "title": "Example data analysis",
    "section": "",
    "text": "Principal functions reading data into R\n\nread.table, read.csv (tabular data)\nreadLines (text file)\nload (read in saved workspaces)\nsource (for reading in R code files)\n\n\n\n\nread.table() is one of the most commonly used functions for reading data. The help file is definitely worth reading in its entirety.\nThe read.table() function has a few important arguments:\n\nfile, the name of a file, or a connection\nheader, logical indicating if the file has a header line\nsep, a string indicating how the columns are separated\ncolClasses, a character vector indicating the class of each column in the dataset\nnrows, the number of rows in the dataset. By default read.table() reads an entire file.\ncomment.char, a character string indicating the comment character. This defaults to “#”.\nskip, the number of lines to skip from the beginning\nstringsAsFactors, should character variables be coded as factors? This defaults to TRUE.\n\n\n\n\n\n\n\n\nTip\n\n\n\nReading larger datasets with R\nread.table() automatically estimates various parameters to store data. If you provide these this significantly speeds up the reading of large data sets.\n\nSet comment.char = \"\" if there are no commented lines in your file.\nUse the colClasses argument. Specifying this option instead of using the default can make ‘read.table’ run MUCH faster, often twice as fast. In order to use this option, you have to know the class of each column in your data frame. If all of the columns are “numeric”, for example, then you can just set colClasses = \"numeric\".\nSet nrows. This doesn’t make R run faster but it helps with memory usage. A mild overestimate is okay.\n\n\n\n\n\n\n\n# use default parameters, missing parameters are estimated\ndata &lt;- read.table(file = \"data/my_data.txt\") \n\n# assign parameters\ndata &lt;- read.table(file = \"data/my_data.txt\", \n                   comment.char = \"\", \n                   header = TRUE,\n                   colClasses = c(rep(\"numeric\",4), \"factor\")\n                   )"
  },
  {
    "objectID": "Trainings/Introduction_to_R/Example_data_analysis.html#import-data",
    "href": "Trainings/Introduction_to_R/Example_data_analysis.html#import-data",
    "title": "Example data analysis",
    "section": "",
    "text": "Principal functions reading data into R\n\nread.table, read.csv (tabular data)\nreadLines (text file)\nload (read in saved workspaces)\nsource (for reading in R code files)\n\n\n\n\nread.table() is one of the most commonly used functions for reading data. The help file is definitely worth reading in its entirety.\nThe read.table() function has a few important arguments:\n\nfile, the name of a file, or a connection\nheader, logical indicating if the file has a header line\nsep, a string indicating how the columns are separated\ncolClasses, a character vector indicating the class of each column in the dataset\nnrows, the number of rows in the dataset. By default read.table() reads an entire file.\ncomment.char, a character string indicating the comment character. This defaults to “#”.\nskip, the number of lines to skip from the beginning\nstringsAsFactors, should character variables be coded as factors? This defaults to TRUE.\n\n\n\n\n\n\n\n\nTip\n\n\n\nReading larger datasets with R\nread.table() automatically estimates various parameters to store data. If you provide these this significantly speeds up the reading of large data sets.\n\nSet comment.char = \"\" if there are no commented lines in your file.\nUse the colClasses argument. Specifying this option instead of using the default can make ‘read.table’ run MUCH faster, often twice as fast. In order to use this option, you have to know the class of each column in your data frame. If all of the columns are “numeric”, for example, then you can just set colClasses = \"numeric\".\nSet nrows. This doesn’t make R run faster but it helps with memory usage. A mild overestimate is okay.\n\n\n\n\n\n\n\n# use default parameters, missing parameters are estimated\ndata &lt;- read.table(file = \"data/my_data.txt\") \n\n# assign parameters\ndata &lt;- read.table(file = \"data/my_data.txt\", \n                   comment.char = \"\", \n                   header = TRUE,\n                   colClasses = c(rep(\"numeric\",4), \"factor\")\n                   )"
  },
  {
    "objectID": "Trainings/Introduction_to_R/Example_data_analysis.html#data-qc-and-exploration",
    "href": "Trainings/Introduction_to_R/Example_data_analysis.html#data-qc-and-exploration",
    "title": "Example data analysis",
    "section": "2. Data QC and exploration",
    "text": "2. Data QC and exploration\nOnce you have imported your data it is always a good idea to inspect your data object:\n\nhead() = displays the first parts of an object\nattributes() = lists the attributes of an object\nstr() = displays the internal structure of an R object or a diagnostic function\nRStudio viewer view()\n\nYou may need to adjust the way you import your data!\n\nNow, you can start exploring your data\n\n# rename the object\niris &lt;- data\n\n# basic summary statistics\nsummary(iris)\n\n# density distribution\nplot(density(iris$Sepal.Length))\n\n# value distribution by group\nboxplot(iris$Sepal.Length ~ iris$Species, col = c(\"black\",\"red\",\"green\"))\n\n# pairwise value plots\npairs(iris, col = iris$Species)"
  },
  {
    "objectID": "Trainings/Introduction_to_R/Example_data_analysis.html#data-analysis",
    "href": "Trainings/Introduction_to_R/Example_data_analysis.html#data-analysis",
    "title": "Example data analysis",
    "section": "3. Data analysis",
    "text": "3. Data analysis\nLets find out how Sepal length and Petal length are related\n\n# examine the relationship between Sepal and Petal Length\nplot(iris$Sepal.Length, iris$Petal.Length, col = iris$Species)\n\n# calculate Pearson correlation\ncor.test(iris$Sepal.Length, iris$Petal.Length)\n\n# =&gt; Great! Sepal.Length and Petal.Length are significantly positive correlated. Let's capture this\n# insight in a nicer informative plot.\n\n\n# FINAL PLOT\n \nplot(iris$Sepal.Length, iris$Petal.Length,            # x variable, y variable\n     col  = iris$Species,                             # colour by species\n     pch  = 16,                                       # type of point to use\n     xlab = \"Sepal Length\",                           # x axis label\n     ylab = \"Petal Length\",                           # y axis label\n     main = \"Flower characteristics in Iris\")         # plot title \n\n# legend with titles of iris$Species and colour 1:3, point type pch at coords (x,y)\nlegend(\"topleft\", legend = levels(iris$Species), col = c(1:3), pch =16)\n\n# text at coords (x,y) with label correlation test\ntext(x = 7.5, y = 2, labels = \"cor = 0.871\\np &lt; 2.2e-16\")\n\nFor more on basic R plots see R Base Graphics: An Idiots Guide"
  },
  {
    "objectID": "Trainings/Introduction_to_R/Example_data_analysis.html#export-results",
    "href": "Trainings/Introduction_to_R/Example_data_analysis.html#export-results",
    "title": "Example data analysis",
    "section": "4. Export results",
    "text": "4. Export results\nAfter you have finished you analysis you may want so save your results for later:\nSaving images\n\nexport with RStudio through Plots &gt;&gt; save\nalternatively use jpeg(), png(), svg() or pdf()\n\n\n# open graphics device\npng(file = \"my_plot.png\", width = 480, height = 480)\n\n# plot\nplot(iris$Sepal.Length, iris$Petal.Length,            # x variable, y variable\n     col  = iris$Species,                             # colour by species\n     pch  = 16,                                       # type of point to use\n     xlab = \"Sepal Length\",                           # x axis label\n     ylab = \"Petal Length\",                           # y axis label\n     main = \"Flower characteristics in Iris\")         # plot title \n\n# legend with titles of iris$Species and colour 1:3, point type pch at coords (x,y)\nlegend(\"topleft\", legend = levels(iris$Species), col = c(1:3), pch =16)\n\n# text at coords (x,y) with label correlation test\ntext(x = 7.5, y = 2, labels = \"cor = 0.871\\np &lt; 2.2e-16\")\n\n# close the device\ndev.off()\n\nFunctions for writing data to files\n\nwrite.table or write.csv (writing tabular data to text files, i.e. CSV, or connections)\nwriteLines(writing character data line-by-line to a file or connection)\nsave (saving an arbitrary number of R objects in binary format (possibly compressed) to a file)\n\n\n# write your results to a file\nwrite.table(iris,                       # dataframe\n            file = \"results.csv\",       # filename\n            sep  = \";\",                 # field seperator\n            col.names = TRUE,           # include header (default = TRUE)\n            row.names = FALSE,          # include row names (default = TRUE)\n            quote = FALSE)              # quote characters and factors\n\n# save your workspace\nsave(file = \"my_workspace.Rdata\")       # warning: this occupies the most space\n\n# save multiple objects\nsave(iris, data, file = \"my_two_objects.Rdata\")\n\n# save a single data object (compressed)\nsaveRDS(iris,                           #  data object\n        file = \"iris.rds\")              #  file name"
  },
  {
    "objectID": "Trainings/0Basic_concepts.html",
    "href": "Trainings/0Basic_concepts.html",
    "title": "Basic concepts",
    "section": "",
    "text": "rstudio: -import data: -quarto: -viewer: -github: -options:\nfunction: -arguments -return -environment*"
  },
  {
    "objectID": "Trainings/Introduction_to_Linux/Linux_exercises.postJune2024.html",
    "href": "Trainings/Introduction_to_Linux/Linux_exercises.postJune2024.html",
    "title": "Introduction to Linux - Exercises",
    "section": "",
    "text": "Exercise 1:\nGo to the root directory and list its content. How many other files aside from directories ? How many directories starting with ‘s’?\nAnswer\n cd /\n ls .      # 1 regular files, 6 softlinks\n ls -d s*  # 4 directories, \n           # Note that `ls s*` will list the contents of all directories\n           # starting with 's\"' \n\n\nExercise 2:\nIn your home directory create a new directory called ‘analysis’. Copy the file ‘/home/shared/peaks.bed’ to this directory. Now, create a softlink to the original file and call it ‘softlink_peaks.bed’.\nFinally, list all files that end with ‘.bed’ in a single command.\nAnswer\n# go to your home directory\n cd ~\n\n# create directory\n mkdir analysis                     \n\n# enter 'analysis' directory \n cd analysis\n \n# copy 'peaks.bed' to current directory \n cp /home/shared/peaks.bed .  \n\n# create softlink \n ln -s /home/shared/peaks.bed -n softlink_peaks.bed  \n\n# list all files ending in '.bed' in all three directories\n ls *.bed\n\n\nExercise 3:\nIs bzip2 or gzip the better compression? Which algorithm compresses peaks.bed more?\nAnswer\n# create two extra copies of 'peaks.bed'\n cp peaks.bed peaks1.bed\n cp peaks.bed peaks2.bed\n\n# compress one file with gzip\n gzip peaks1.bed\n\n# compress the other file wit bzip2\n bzip2 peaks2.bed\n\n# compare file sizes with ls\n ls -lth\n\n# =&gt; the file compressed with bzip2 is slightly smaller (6.1K) than the one compressed with gzip (6.4K)\n\n\nExercise 4\nExtract the first and last 10 lines of the file peaks.bed into a new file. How many characters does this file have?\nAnswer\n# extract the first 10 lines\n head -10 peaks.bed &gt; head.peaks\n \n# extract the last 10 lines and append to the previous file\n tail -10 peaks.bed &gt;&gt; head.peaks\n \n# count the number of characters\n wc -c head.peaks\n\n\nExercise 5:\nExtract the first 10 lines of the second and fifth column from of peaks.bed. Create a file where the (originally) second column is sorted by increasing size and the fifth column by decreasing size.\nHow many characters does the last line of this file have?\nAnswer\n# extract the first 10 lines, slice column 2, sort numerical and store output in a file\n head -10 peaks.bed | cut -f 2 |sort -n &gt; column2\n\n# do the same but with column 5 and sort in reverse order.\n# then join output with previous file, extract last line and count number of characters (=12)\n head -10 peaks.bed | cut -f 5 |sort -nr| paste column 2 - | tail -1| wc -c\n\n\nExercise 6:\nWhat is the highest and lowest value in column 5 on chrM?\nAnswer\n# find all lines with pattern 'chrM', slice column 5, sort numerical, \n# extract first and last line\ngrep -w chrM peaks.bed | cut -f 5| sort -n| head -1\ngrep -w chrM peaks.bed | cut -f 5| sort -n| tail -1\n\n\nExercise 7:\nWrite a script, that for any given directory lists all files it contains and counts the number of characters of all regular files it contains.\nAnswer\n#! /bin/bash\n\n### Author: Angelika Merkel\n### Date: 30/11/2022\n\n###############################################################################\n### Description:\n### Script script, that for any given directory lists all files it contains and\n### counts the number of characters of all regular files it contains.\n\n###############################################################################\n# assign the script's first argument to a meaningful variable\nDIR=$1\n\n# loop over all elements listed in the specified directory\nfor i in `ls $DIR`\n do\n \n # test if the element listed is a regular file (else could be a directory)\n  if [ -f \"$i\" ]                         \n  \n  # if true, count all characters within the file and return with a message\n    then\n      CHAR=`cat $i| wc -c`\n      echo $i \":\" $CHAR \"characters\"\n  \n  # close conditional\n  fi\n  \n# close for loop\ndone\nFinally, to run the script:\n chmod a+x myscript.sh       # make the file executable\n ./myscript.sh               # run"
  },
  {
    "objectID": "Trainings/Visualizations_with_ggplot2/Visualizations_with_ggplot2.html",
    "href": "Trainings/Visualizations_with_ggplot2/Visualizations_with_ggplot2.html",
    "title": "Data visualization in R with the ggplot2 package",
    "section": "",
    "text": "This workshop introduces the ggplot2 R package for data visualization ( course presentation available here)\nTopics covered:\n\nWhy ggplot2?\nBase R and the tidyverse\nBuilding up your plot with ggplot()\nAestetics and geoms\nTypes of plots for one, two or multiple numerical/categorical variables\n\nFor this course we follow the Chapter: ‘Data visualization’ in the book R for Data Science (2nd edition) by Wickham et al. This includes the practical session and exercises.",
    "crumbs": [
      "Trainings",
      "R",
      "Visualizations with ggplot2"
    ]
  },
  {
    "objectID": "Trainings/Advancing_with_the_Shell/Advancing_with_the_Shell.html",
    "href": "Trainings/Advancing_with_the_Shell/Advancing_with_the_Shell.html",
    "title": "Advancing with the Shell",
    "section": "",
    "text": "In this course we teach advanced functionality of the shell (specifically bash). The course presentation is available here\nTopics covered:\n\nCustomizing your Shell\nBash: Expansions ans substitution\nRegular expression\nFile manipulations with awk and sed",
    "crumbs": [
      "Trainings",
      "Linux/Shell",
      "The Shell advanced"
    ]
  }
]